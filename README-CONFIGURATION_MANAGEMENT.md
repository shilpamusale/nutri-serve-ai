# âš™ï¸ Configuration Management with Hydra

This project uses [Hydra](https://hydra.cc) for structured, hierarchical configuration with environment-specific overrides.

---

## ğŸ“‚ Directory Structure

```
src/ms_potts/conf/
â”œâ”€â”€ config.yaml              # Main configuration
â”œâ”€â”€ development/
â”‚   â””â”€â”€ config.yaml          # Development overrides
â”œâ”€â”€ production/
â”‚   â””â”€â”€ config.yaml          # Production overrides
â””â”€â”€ testing/
    â””â”€â”€ config.yaml          # Testing overrides
```

---

## ğŸ§  Features

- Single source of truth (`conf/config.yaml`)
- Environment overrides (e.g., `+mode=development`)
- Command-line overrides for experiments
- Environment variable integration (e.g., `${oc.env:GEMINI_API_KEY}`)

---

## ğŸ§ª Example Usage

### â–¶ï¸ Run with development configuration

```bash
python -m src.ms_potts.main +mode=development
```

### ğŸ¯ Override model settings

```bash
python -m src.ms_potts.main model.temperature=0.3 model.max_tokens=2048
```

### ğŸ›  Change port and log level

```bash
python -m src.ms_potts.main app.port=9000 logging.level=debug
```

---

## âœ… Decorator Usage

```python
@hydra.main(config_path="conf", config_name="config")
def main(cfg: DictConfig):
    print(OmegaConf.to_yaml(cfg))
```

---

## ğŸ“˜ Key Configuration Values

```yaml
model:
  name: sentence-transformers
  model_path: all-MiniLM-L6-v2
  use_gpu: true
  temperature: 0.2

gemini:
  model_name: gemini-1.5-flash
  max_tokens: 1024

app:
  host: 0.0.0.0
  port: 8080
```

Use Hydraâ€™s flexibility to experiment, switch environments, and keep your code clean!
